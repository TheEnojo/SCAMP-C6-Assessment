# SCAMP-C6-Assessment
SCA Technical Assessment
The given dataset contains a collection of job postings, some of which are fraudulent. The data contains textual & meta info about these jobs. I am going to clean and scale the data and also study the details of the dataset.


Variable	Description <br>

job_id:                 ID of each job posting<br>

title:	                     Description of position or job<br>

location:	             Where the job is located <br>

department:	         Department of the job offered<br>

salary_range:	       Expected salary range<br>

company_profile:	    Company information<br>

benefits:	               Benefits provided by the job<br>

telecommuting:	     Is work from home or remote work allowed<br>

description	:              Description about the position offered<br>

requirements:	        Pre-requisites to qualify for the job

has_company_logo:    Does the post have a company logo<br>

has_questions:	         Does the post have any questions<br>
employment_type:	     Full-time, part-time, contract, temporary and others<br>

required_experience:	  Experience level, e.g. Entry level, Executive, Director…<br>

required_education:    Education level, e.g. High School, Bachelor, Master…<br>

industry:	                  Relevant industry<br>

function:	                  Job’s functionality<br>

fraudulent:	                 Target variable (0: Real, 1: Fake)<br>


## Objectives

1)Find out which industry has the highest number of fake job postings. <br>

2)Graphically display my answer


## Python libaries used:
Pandas
Numpy
Seaborn
Matplotlib

